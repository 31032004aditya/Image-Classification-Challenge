{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"#### Importing Libraries","metadata":{"execution":{"iopub.status.busy":"2022-10-19T14:36:23.497413Z","iopub.execute_input":"2022-10-19T14:36:23.498434Z","iopub.status.idle":"2022-10-19T14:36:23.565483Z","shell.execute_reply.started":"2022-10-19T14:36:23.49839Z","shell.execute_reply":"2022-10-19T14:36:23.564509Z"}}},{"cell_type":"code","source":"!pip install timm","metadata":{"_kg_hide-output":true,"execution":{"iopub.status.busy":"2022-10-24T06:30:04.443636Z","iopub.execute_input":"2022-10-24T06:30:04.444058Z","iopub.status.idle":"2022-10-24T06:30:16.721085Z","shell.execute_reply.started":"2022-10-24T06:30:04.443967Z","shell.execute_reply":"2022-10-24T06:30:16.719926Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"Collecting timm\n  Downloading timm-0.6.11-py3-none-any.whl (548 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m548.7/548.7 kB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[?25hRequirement already satisfied: huggingface-hub in /opt/conda/lib/python3.7/site-packages (from timm) (0.8.1)\nRequirement already satisfied: torchvision in /opt/conda/lib/python3.7/site-packages (from timm) (0.12.0)\nRequirement already satisfied: pyyaml in /opt/conda/lib/python3.7/site-packages (from timm) (6.0)\nRequirement already satisfied: torch>=1.7 in /opt/conda/lib/python3.7/site-packages (from timm) (1.11.0)\nRequirement already satisfied: typing-extensions in /opt/conda/lib/python3.7/site-packages (from torch>=1.7->timm) (4.3.0)\nRequirement already satisfied: importlib-metadata in /opt/conda/lib/python3.7/site-packages (from huggingface-hub->timm) (4.12.0)\nRequirement already satisfied: tqdm in /opt/conda/lib/python3.7/site-packages (from huggingface-hub->timm) (4.64.0)\nRequirement already satisfied: packaging>=20.9 in /opt/conda/lib/python3.7/site-packages (from huggingface-hub->timm) (21.3)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.7/site-packages (from huggingface-hub->timm) (3.7.1)\nRequirement already satisfied: requests in /opt/conda/lib/python3.7/site-packages (from huggingface-hub->timm) (2.28.1)\nRequirement already satisfied: pillow!=8.3.*,>=5.3.0 in /opt/conda/lib/python3.7/site-packages (from torchvision->timm) (9.1.1)\nRequirement already satisfied: numpy in /opt/conda/lib/python3.7/site-packages (from torchvision->timm) (1.21.6)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.7/site-packages (from packaging>=20.9->huggingface-hub->timm) (3.0.9)\nRequirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata->huggingface-hub->timm) (3.8.0)\nRequirement already satisfied: charset-normalizer<3,>=2 in /opt/conda/lib/python3.7/site-packages (from requests->huggingface-hub->timm) (2.1.0)\nRequirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests->huggingface-hub->timm) (1.26.12)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests->huggingface-hub->timm) (3.3)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests->huggingface-hub->timm) (2022.6.15.2)\nInstalling collected packages: timm\nSuccessfully installed timm-0.6.11\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0m","output_type":"stream"}]},{"cell_type":"code","source":"# timm.list_models(pretrained = True)","metadata":{"execution":{"iopub.status.busy":"2022-10-24T06:30:16.723622Z","iopub.execute_input":"2022-10-24T06:30:16.725424Z","iopub.status.idle":"2022-10-24T06:30:16.730803Z","shell.execute_reply.started":"2022-10-24T06:30:16.725381Z","shell.execute_reply":"2022-10-24T06:30:16.729942Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"markdown","source":"# Libraries","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom statistics import mean\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score\nimport cv2\n\nimport timm\nfrom tqdm import tqdm\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torch.optim import Adam, SGD\nimport torchvision.models as models\nfrom torch.utils.data import DataLoader, Dataset\nfrom torch.optim.lr_scheduler import StepLR\n\nimport albumentations as A\nfrom albumentations.pytorch import ToTensorV2\n\nimport warnings\nwarnings.filterwarnings('ignore')","metadata":{"execution":{"iopub.status.busy":"2022-10-24T06:30:16.732775Z","iopub.execute_input":"2022-10-24T06:30:16.733232Z","iopub.status.idle":"2022-10-24T06:30:20.822572Z","shell.execute_reply.started":"2022-10-24T06:30:16.733193Z","shell.execute_reply":"2022-10-24T06:30:20.821428Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")","metadata":{"execution":{"iopub.status.busy":"2022-10-24T06:30:20.824078Z","iopub.execute_input":"2022-10-24T06:30:20.824683Z","iopub.status.idle":"2022-10-24T06:30:20.894396Z","shell.execute_reply.started":"2022-10-24T06:30:20.824651Z","shell.execute_reply":"2022-10-24T06:30:20.893481Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"markdown","source":"# Dataset","metadata":{}},{"cell_type":"markdown","source":"#### Data Analysis\n* concetto_CDT contains images of hand-drawn clock\n* train_csv contain the corrsponding image id and their labels\n* test_csv contain the images which needs to be predicted","metadata":{}},{"cell_type":"code","source":"train = pd.read_csv('../input/concetto22/train.csv')\ntest = pd.read_csv('../input/concetto22/test.csv')","metadata":{"execution":{"iopub.status.busy":"2022-10-24T06:30:20.897923Z","iopub.execute_input":"2022-10-24T06:30:20.898300Z","iopub.status.idle":"2022-10-24T06:30:20.927043Z","shell.execute_reply.started":"2022-10-24T06:30:20.898263Z","shell.execute_reply":"2022-10-24T06:30:20.926072Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"train.head()","metadata":{"execution":{"iopub.status.busy":"2022-10-24T06:30:20.928291Z","iopub.execute_input":"2022-10-24T06:30:20.928645Z","iopub.status.idle":"2022-10-24T06:30:20.948399Z","shell.execute_reply.started":"2022-10-24T06:30:20.928612Z","shell.execute_reply":"2022-10-24T06:30:20.947363Z"},"trusted":true},"execution_count":6,"outputs":[{"execution_count":6,"output_type":"execute_result","data":{"text/plain":"           id  tar\n0  20002859.0  5.0\n1  10011157.0  5.0\n2  10011996.0  5.0\n3  10000364.0  5.0\n4  20004294.0  3.0","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>tar</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>20002859.0</td>\n      <td>5.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>10011157.0</td>\n      <td>5.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>10011996.0</td>\n      <td>5.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>10000364.0</td>\n      <td>5.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>20004294.0</td>\n      <td>3.0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"test.head()","metadata":{"execution":{"iopub.status.busy":"2022-10-24T06:30:20.949700Z","iopub.execute_input":"2022-10-24T06:30:20.950598Z","iopub.status.idle":"2022-10-24T06:30:20.960584Z","shell.execute_reply.started":"2022-10-24T06:30:20.950564Z","shell.execute_reply":"2022-10-24T06:30:20.959444Z"},"trusted":true},"execution_count":7,"outputs":[{"execution_count":7,"output_type":"execute_result","data":{"text/plain":"           id\n0  10002998.0\n1  10003172.0\n2  20004712.0\n3  20004205.0\n4  20000346.0","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>10002998.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>10003172.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>20004712.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>20004205.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>20000346.0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"# This function adds an extra column having the path of the images\ndef append_path(df):\n    target_str = []\n    for i in range(len(df)):\n        target_str.append(str(df['id'][i]))\n    for i in range(len(df)):\n        target_str[i] = target_str[i].replace('.0', '.tif') \n        target_str[i] = '/kaggle/input/concetto22/concetto_CDT/concetto_CDT/'+target_str[i]\n    df['path'] = target_str\n    return df","metadata":{"execution":{"iopub.status.busy":"2022-10-24T06:30:20.962031Z","iopub.execute_input":"2022-10-24T06:30:20.962897Z","iopub.status.idle":"2022-10-24T06:30:20.970525Z","shell.execute_reply.started":"2022-10-24T06:30:20.962860Z","shell.execute_reply":"2022-10-24T06:30:20.969532Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"train = append_path(train)\ntrain.head()","metadata":{"execution":{"iopub.status.busy":"2022-10-24T06:30:20.971957Z","iopub.execute_input":"2022-10-24T06:30:20.972849Z","iopub.status.idle":"2022-10-24T06:30:21.008172Z","shell.execute_reply.started":"2022-10-24T06:30:20.972814Z","shell.execute_reply":"2022-10-24T06:30:21.007043Z"},"trusted":true},"execution_count":9,"outputs":[{"execution_count":9,"output_type":"execute_result","data":{"text/plain":"           id  tar                                               path\n0  20002859.0  5.0  /kaggle/input/concetto22/concetto_CDT/concetto...\n1  10011157.0  5.0  /kaggle/input/concetto22/concetto_CDT/concetto...\n2  10011996.0  5.0  /kaggle/input/concetto22/concetto_CDT/concetto...\n3  10000364.0  5.0  /kaggle/input/concetto22/concetto_CDT/concetto...\n4  20004294.0  3.0  /kaggle/input/concetto22/concetto_CDT/concetto...","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>tar</th>\n      <th>path</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>20002859.0</td>\n      <td>5.0</td>\n      <td>/kaggle/input/concetto22/concetto_CDT/concetto...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>10011157.0</td>\n      <td>5.0</td>\n      <td>/kaggle/input/concetto22/concetto_CDT/concetto...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>10011996.0</td>\n      <td>5.0</td>\n      <td>/kaggle/input/concetto22/concetto_CDT/concetto...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>10000364.0</td>\n      <td>5.0</td>\n      <td>/kaggle/input/concetto22/concetto_CDT/concetto...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>20004294.0</td>\n      <td>3.0</td>\n      <td>/kaggle/input/concetto22/concetto_CDT/concetto...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"test = append_path(test)\ntest.head()","metadata":{"execution":{"iopub.status.busy":"2022-10-24T06:30:21.009333Z","iopub.execute_input":"2022-10-24T06:30:21.010680Z","iopub.status.idle":"2022-10-24T06:30:21.026608Z","shell.execute_reply.started":"2022-10-24T06:30:21.010641Z","shell.execute_reply":"2022-10-24T06:30:21.025526Z"},"trusted":true},"execution_count":10,"outputs":[{"execution_count":10,"output_type":"execute_result","data":{"text/plain":"           id                                               path\n0  10002998.0  /kaggle/input/concetto22/concetto_CDT/concetto...\n1  10003172.0  /kaggle/input/concetto22/concetto_CDT/concetto...\n2  20004712.0  /kaggle/input/concetto22/concetto_CDT/concetto...\n3  20004205.0  /kaggle/input/concetto22/concetto_CDT/concetto...\n4  20000346.0  /kaggle/input/concetto22/concetto_CDT/concetto...","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>path</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>10002998.0</td>\n      <td>/kaggle/input/concetto22/concetto_CDT/concetto...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>10003172.0</td>\n      <td>/kaggle/input/concetto22/concetto_CDT/concetto...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>20004712.0</td>\n      <td>/kaggle/input/concetto22/concetto_CDT/concetto...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>20004205.0</td>\n      <td>/kaggle/input/concetto22/concetto_CDT/concetto...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>20000346.0</td>\n      <td>/kaggle/input/concetto22/concetto_CDT/concetto...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"markdown","source":"#### Data visualization","metadata":{}},{"cell_type":"code","source":"plt.imshow(cv2.imread(train['path'][0]))","metadata":{"execution":{"iopub.status.busy":"2022-10-24T06:30:21.028406Z","iopub.execute_input":"2022-10-24T06:30:21.028781Z","iopub.status.idle":"2022-10-24T06:30:22.580475Z","shell.execute_reply.started":"2022-10-24T06:30:21.028744Z","shell.execute_reply":"2022-10-24T06:30:22.579519Z"},"trusted":true},"execution_count":11,"outputs":[{"execution_count":11,"output_type":"execute_result","data":{"text/plain":"<matplotlib.image.AxesImage at 0x7f783e97b0d0>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<Figure size 432x288 with 1 Axes>","image/png":"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\n"},"metadata":{"needs_background":"light"}}]},{"cell_type":"markdown","source":"#### Splitting the train data into train and val set","metadata":{}},{"cell_type":"code","source":"X = train.drop(['tar'], axis=1)\ny = train['tar']\nx_train, x_val, y_train, y_val = train_test_split(X, y, test_size=0.1, random_state=42, stratify = y)","metadata":{"execution":{"iopub.status.busy":"2022-10-24T06:30:22.581885Z","iopub.execute_input":"2022-10-24T06:30:22.582675Z","iopub.status.idle":"2022-10-24T06:30:22.597129Z","shell.execute_reply.started":"2022-10-24T06:30:22.582637Z","shell.execute_reply":"2022-10-24T06:30:22.596148Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"train_data = pd.merge(x_train, y_train, right_index=True, left_index=True)\nval_data = pd.merge(x_val, y_val, right_index=True, left_index=True)","metadata":{"execution":{"iopub.status.busy":"2022-10-24T06:30:22.598972Z","iopub.execute_input":"2022-10-24T06:30:22.599347Z","iopub.status.idle":"2022-10-24T06:30:22.616502Z","shell.execute_reply.started":"2022-10-24T06:30:22.599309Z","shell.execute_reply":"2022-10-24T06:30:22.615503Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"#defining a configuration\n\nclass CFG:\n    model_name = 'densenet161'\n    target_size = 6\n    size = 264\n    batch_size = 12\n    epochs = 15\n    num_workers = 2\n    lr = 1e-4\n    weight_decay = 1e-2\n    train = True\n    target_col = 'tar'","metadata":{"execution":{"iopub.status.busy":"2022-10-24T06:30:22.624013Z","iopub.execute_input":"2022-10-24T06:30:22.624293Z","iopub.status.idle":"2022-10-24T06:30:22.632272Z","shell.execute_reply.started":"2022-10-24T06:30:22.624267Z","shell.execute_reply":"2022-10-24T06:30:22.631369Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"markdown","source":"#### Dataset creation \nCreating a custom dataset for training and test data which takes path of images, transforms it and converts the image to tensors for further processing.","metadata":{}},{"cell_type":"code","source":"class TrainDataset(Dataset):\n    def __init__(self, df, transform=None):\n        self.df = df\n        self.file_names = df['path'].values\n        self.labels = df['tar'].values\n        self.transform = transform\n        \n    def __len__(self):\n        return len(self.df)\n\n    def __getitem__(self, idx):\n        file_name = self.file_names[idx]\n        file_path = file_name\n        image = cv2.imread(file_path)\n        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n        if self.transform:\n            augmented = self.transform(image=image)\n            image = augmented['image']\n        label = torch.tensor(self.labels[idx]).long()\n        return image, label\n    \n\nclass TestDataset(Dataset):\n    def __init__(self, df, transform=None):\n        self.df = df\n        self.file_names = df['path'].values\n        self.transform = transform\n        \n    def __len__(self):\n        return len(self.df)\n\n    def __getitem__(self, idx):\n        file_name = self.file_names[idx]\n        file_path = file_name\n        image = cv2.imread(file_path)\n        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n        if self.transform:\n            augmented = self.transform(image=image)\n            image = augmented['image']\n        return image","metadata":{"execution":{"iopub.status.busy":"2022-10-24T06:30:22.634052Z","iopub.execute_input":"2022-10-24T06:30:22.634416Z","iopub.status.idle":"2022-10-24T06:30:22.647921Z","shell.execute_reply.started":"2022-10-24T06:30:22.634382Z","shell.execute_reply":"2022-10-24T06:30:22.646617Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"markdown","source":"# Transformation","metadata":{}},{"cell_type":"markdown","source":"#### Augmentation\nApplying some necessary augmentations like resizing the image to the size accepted by model, Normalizing the tensors.\nAlbumentations like RandomResizedCrop and HorizontalFlip are used to augment the dataset.\nFind more albumentations [here](https://github.com/pytorch/vision/blob/main/torchvision/transforms/transforms.py)","metadata":{}},{"cell_type":"code","source":"# Transforms\ndef get_transforms(*, data):\n    \n    if data == 'train':\n        return A.Compose([\n            A.Resize(CFG.size, CFG.size),\n            A.RandomResizedCrop(CFG.size, CFG.size),\n            A.HorizontalFlip(p=0.5),\n            A.Normalize(\n                mean=[0.485, 0.456, 0.406],\n                std=[0.229, 0.224, 0.225],\n            ),\n            ToTensorV2(),\n        ])\n\n    elif data == 'valid':\n        return A.Compose([\n            A.Resize(CFG.size, CFG.size),\n            A.Normalize(\n                mean=[0.485, 0.456, 0.406],\n                std=[0.229, 0.224, 0.225],\n            ),\n            ToTensorV2(),\n        ])","metadata":{"execution":{"iopub.status.busy":"2022-10-24T06:30:22.649032Z","iopub.execute_input":"2022-10-24T06:30:22.649331Z","iopub.status.idle":"2022-10-24T06:30:22.660773Z","shell.execute_reply.started":"2022-10-24T06:30:22.649291Z","shell.execute_reply":"2022-10-24T06:30:22.659786Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"markdown","source":"# Model","metadata":{}},{"cell_type":"code","source":"class CustomNet(nn.Module):\n    def __init__(self, model_name=CFG.model_name, pretrained=False):\n        super().__init__()\n        self.model = timm.create_model(CFG.model_name, pretrained=pretrained)\n        #print(self.model.default_cfg[\"classifier\"])\n        n_features = self.model.classifier.in_features #either fc or classifier , check using above line\n        self.model.classifier = nn.Linear(n_features, CFG.target_size)\n\n    def forward(self, x):\n        x = self.model(x)\n        return x\n    ","metadata":{"execution":{"iopub.status.busy":"2022-10-24T06:30:22.662186Z","iopub.execute_input":"2022-10-24T06:30:22.662692Z","iopub.status.idle":"2022-10-24T06:30:22.671335Z","shell.execute_reply.started":"2022-10-24T06:30:22.662656Z","shell.execute_reply":"2022-10-24T06:30:22.670177Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"model = CustomNet(model_name=CFG.model_name, pretrained=True)","metadata":{"execution":{"iopub.status.busy":"2022-10-24T06:30:22.672889Z","iopub.execute_input":"2022-10-24T06:30:22.673248Z","iopub.status.idle":"2022-10-24T06:30:24.476549Z","shell.execute_reply.started":"2022-10-24T06:30:22.673212Z","shell.execute_reply":"2022-10-24T06:30:24.475574Z"},"trusted":true},"execution_count":18,"outputs":[{"name":"stderr","text":"Downloading: \"https://download.pytorch.org/models/densenet161-8d451a50.pth\" to /root/.cache/torch/hub/checkpoints/densenet161-8d451a50.pth\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## Loss Function\nThe loss function used, here [CrossEntropyloss.](https://pytorch.org/docs/stable/generated/torch.nn.CrossEntropyLoss.html)","metadata":{}},{"cell_type":"code","source":"def get_criterion():\n    \n    criterion = nn.CrossEntropyLoss() \n\n    return criterion","metadata":{"execution":{"iopub.status.busy":"2022-10-24T06:30:24.477895Z","iopub.execute_input":"2022-10-24T06:30:24.478268Z","iopub.status.idle":"2022-10-24T06:30:24.483185Z","shell.execute_reply.started":"2022-10-24T06:30:24.478231Z","shell.execute_reply":"2022-10-24T06:30:24.482264Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"def get_score(y_true, y_pred):\n    return accuracy_score(y_true, y_pred)","metadata":{"execution":{"iopub.status.busy":"2022-10-24T06:30:24.484510Z","iopub.execute_input":"2022-10-24T06:30:24.485524Z","iopub.status.idle":"2022-10-24T06:30:24.494357Z","shell.execute_reply.started":"2022-10-24T06:30:24.485488Z","shell.execute_reply":"2022-10-24T06:30:24.493503Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"markdown","source":"## Optimizer","metadata":{}},{"cell_type":"code","source":"def get_optimizer(model):\n    optimizer = Adam(model.parameters(), lr=CFG.lr, weight_decay=CFG.weight_decay, amsgrad=False)\n    return optimizer","metadata":{"execution":{"iopub.status.busy":"2022-10-24T06:30:24.495582Z","iopub.execute_input":"2022-10-24T06:30:24.496495Z","iopub.status.idle":"2022-10-24T06:30:24.504430Z","shell.execute_reply.started":"2022-10-24T06:30:24.496442Z","shell.execute_reply":"2022-10-24T06:30:24.503508Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"markdown","source":"## Scheduler\nIt is used for adjusting the learning rate(LR decay) between epochs as the training progresses. Read about more schedulers [here](https://pytorch.org/docs/stable/optim.html#)","metadata":{}},{"cell_type":"code","source":"def get_scheduler(optimizer):\n    scheduler = StepLR(optimizer, step_size=3, gamma=0.01, verbose=True)\n    return scheduler","metadata":{"execution":{"iopub.status.busy":"2022-10-24T06:30:24.505717Z","iopub.execute_input":"2022-10-24T06:30:24.506164Z","iopub.status.idle":"2022-10-24T06:30:24.515283Z","shell.execute_reply.started":"2022-10-24T06:30:24.506128Z","shell.execute_reply":"2022-10-24T06:30:24.514356Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"markdown","source":"## Utility Functions","metadata":{}},{"cell_type":"code","source":"class AverageMeter(object):\n    \"\"\"Computes and stores the average and current value\"\"\"\n    def __init__(self):\n        self.reset()\n\n    def reset(self):\n        self.val = 0\n        self.avg = 0\n        self.sum = 0\n        self.count = 0\n\n    def update(self, val, n=1):\n        self.val = val\n        self.sum += val * n\n        self.count += n\n        self.avg = self.sum / self.count\n        \ndef train_fn(train_loader, model, criterion, optimizer, epoch, scheduler, device):\n    model.train() # switch to training mode\n    running_loss = 0\n    count = 0\n    for (images, labels) in tqdm(train_loader):\n        images = images.to(device)\n        labels = labels.to(device)\n        y_preds = model(images)\n        \n        loss = criterion(y_preds, labels)\n        running_loss += loss.item()*labels.shape[0]\n        count += 1\n        \n        loss.backward()\n        optimizer.step()\n        optimizer.zero_grad()\n        \n    return running_loss/count\n\n\ndef valid_fn(valid_loader, model, criterion, device):\n    model.eval() # switch to evaluation mode\n    preds = []\n    running_loss = 0\n    count = 0\n    \n    for (images, labels) in tqdm(valid_loader):\n        images = images.to(device)\n        labels = labels.to(device)\n        # compute loss\n        with torch.no_grad():\n            y_preds = model(images)\n        loss = criterion(y_preds, labels)\n        running_loss += loss.item()*labels.shape[0]\n        count += 1\n        # record accuracy\n        preds.append(y_preds.softmax(1).to('cpu').numpy())\n    predictions = np.concatenate(preds)\n    \n    return (running_loss/count), predictions\n\n\ndef test_fun(test_loader, model, device):\n    model.eval()\n    preds = []\n    test_df = pd.DataFrame()\n    for step, (images) in enumerate(test_loader):\n        images = images.to(device)\n        with torch.no_grad():\n            y_preds = model(images)\n        preds.append(y_preds.softmax(1).to('cpu').numpy())\n    predictions = np.concatenate(preds)\n    pred = predictions.argmax(1)\n    return pred","metadata":{"execution":{"iopub.status.busy":"2022-10-24T06:30:24.518216Z","iopub.execute_input":"2022-10-24T06:30:24.518602Z","iopub.status.idle":"2022-10-24T06:30:24.532684Z","shell.execute_reply.started":"2022-10-24T06:30:24.518577Z","shell.execute_reply":"2022-10-24T06:30:24.531734Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"markdown","source":"# Train loop","metadata":{}},{"cell_type":"code","source":"# Train loop\ndef train_loop(train_data, valid_data):\n    \n    # create dataset\n    train_dataset = TrainDataset(train_data, transform=get_transforms(data='train'))\n    valid_dataset = TrainDataset(valid_data, transform=get_transforms(data='valid'))\n\n    # create dataloader\n    train_loader = DataLoader(train_dataset, batch_size=CFG.batch_size, shuffle=True, \n                              num_workers=CFG.num_workers, pin_memory=True, drop_last=True)\n    valid_loader = DataLoader(valid_dataset, batch_size=CFG.batch_size, shuffle=False, \n                              num_workers=CFG.num_workers, pin_memory=True, drop_last=False)\n\n    # create model and transfer to device\n    model = CustomNet(CFG.model_name, pretrained=True)\n    model.to(device)\n    \n    # select optimizer, scheduler and criterion\n    optimizer = get_optimizer(model)\n    scheduler = get_scheduler(optimizer)\n    criterion = get_criterion()\n\n    best_score = -1.0\n    best_loss = np.inf\n    \n    # start training\n    for epoch in range(CFG.epochs):\n        # train\n        avg_loss = train_fn(train_loader, model, criterion, optimizer, epoch, scheduler, device)\n        # validation\n        avg_val_loss, preds = valid_fn(valid_loader, model, criterion, device)\n        \n#         valid_labels = valid_folds[CFG.target_col].values\n        valid_labels = valid_data['tar']\n        \n        scheduler.step()\n\n        # scoring\n        score = get_score(valid_labels, preds.argmax(1))\n        print(\"score: \", score)\n\n        # code for saving the best model\n        if score > best_score:\n            print('Score Improved')\n            best_score = score\n            print(f'Epoch {epoch+1} - Save Best Score: {best_score:.4f}')\n            torch.save({'model': model.state_dict(), \n                        'preds': preds,\n                        'optimizer': optimizer.state_dict(),\n                        'scheduler': scheduler.state_dict()},\n                        './'+f'{CFG.model_name}_best.pth')\n    \n    check_point = torch.load('./'+f'{CFG.model_name}_best.pth')\n    valid_data['preds'] = check_point['preds'].argmax(1)\n\n    return valid_data","metadata":{"execution":{"iopub.status.busy":"2022-10-24T06:30:24.534188Z","iopub.execute_input":"2022-10-24T06:30:24.534595Z","iopub.status.idle":"2022-10-24T06:30:24.548586Z","shell.execute_reply.started":"2022-10-24T06:30:24.534554Z","shell.execute_reply":"2022-10-24T06:30:24.547671Z"},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"code","source":"# main\ndef main():\n    def get_result(result_df):\n        preds = result_df['preds'].values\n        labels = result_df[CFG.target_col].values\n        score = get_score(labels, preds)\n    \n    if CFG.train: \n        # train\n        df = train_loop(train_data, val_data)\n        get_result(df)","metadata":{"execution":{"iopub.status.busy":"2022-10-24T06:30:24.550003Z","iopub.execute_input":"2022-10-24T06:30:24.550399Z","iopub.status.idle":"2022-10-24T06:30:24.561654Z","shell.execute_reply.started":"2022-10-24T06:30:24.550363Z","shell.execute_reply":"2022-10-24T06:30:24.560592Z"},"trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"code","source":"if __name__ == '__main__':\n    main()","metadata":{"execution":{"iopub.status.busy":"2022-10-24T06:30:24.563247Z","iopub.execute_input":"2022-10-24T06:30:24.563650Z","iopub.status.idle":"2022-10-24T07:03:32.539179Z","shell.execute_reply.started":"2022-10-24T06:30:24.563613Z","shell.execute_reply":"2022-10-24T07:03:32.538051Z"},"trusted":true},"execution_count":26,"outputs":[{"name":"stdout","text":"Adjusting learning rate of group 0 to 1.0000e-04.\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 190/190 [02:08<00:00,  1.48it/s]\n100%|██████████| 22/22 [00:12<00:00,  1.75it/s]\n","output_type":"stream"},{"name":"stdout","text":"Adjusting learning rate of group 0 to 1.0000e-04.\nscore:  0.48031496062992124\nScore Improved\nEpoch 1 - Save Best Score: 0.4803\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 190/190 [02:01<00:00,  1.57it/s]\n100%|██████████| 22/22 [00:12<00:00,  1.81it/s]\n","output_type":"stream"},{"name":"stdout","text":"Adjusting learning rate of group 0 to 1.0000e-04.\nscore:  0.5078740157480315\nScore Improved\nEpoch 2 - Save Best Score: 0.5079\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 190/190 [02:00<00:00,  1.58it/s]\n100%|██████████| 22/22 [00:11<00:00,  1.87it/s]\n","output_type":"stream"},{"name":"stdout","text":"Adjusting learning rate of group 0 to 1.0000e-06.\nscore:  0.5748031496062992\nScore Improved\nEpoch 3 - Save Best Score: 0.5748\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 190/190 [02:01<00:00,  1.57it/s]\n100%|██████████| 22/22 [00:12<00:00,  1.80it/s]\n","output_type":"stream"},{"name":"stdout","text":"Adjusting learning rate of group 0 to 1.0000e-06.\nscore:  0.5866141732283464\nScore Improved\nEpoch 4 - Save Best Score: 0.5866\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 190/190 [01:59<00:00,  1.59it/s]\n100%|██████████| 22/22 [00:12<00:00,  1.79it/s]\n","output_type":"stream"},{"name":"stdout","text":"Adjusting learning rate of group 0 to 1.0000e-06.\nscore:  0.5708661417322834\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 190/190 [01:59<00:00,  1.59it/s]\n100%|██████████| 22/22 [00:11<00:00,  1.87it/s]\n","output_type":"stream"},{"name":"stdout","text":"Adjusting learning rate of group 0 to 1.0000e-08.\nscore:  0.5905511811023622\nScore Improved\nEpoch 6 - Save Best Score: 0.5906\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 190/190 [01:59<00:00,  1.59it/s]\n100%|██████████| 22/22 [00:11<00:00,  1.89it/s]\n","output_type":"stream"},{"name":"stdout","text":"Adjusting learning rate of group 0 to 1.0000e-08.\nscore:  0.5984251968503937\nScore Improved\nEpoch 7 - Save Best Score: 0.5984\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 190/190 [01:59<00:00,  1.58it/s]\n100%|██████████| 22/22 [00:11<00:00,  1.89it/s]\n","output_type":"stream"},{"name":"stdout","text":"Adjusting learning rate of group 0 to 1.0000e-08.\nscore:  0.5984251968503937\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 190/190 [01:58<00:00,  1.60it/s]\n100%|██████████| 22/22 [00:11<00:00,  1.91it/s]\n","output_type":"stream"},{"name":"stdout","text":"Adjusting learning rate of group 0 to 1.0000e-10.\nscore:  0.594488188976378\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 190/190 [01:58<00:00,  1.60it/s]\n100%|██████████| 22/22 [00:11<00:00,  1.90it/s]\n","output_type":"stream"},{"name":"stdout","text":"Adjusting learning rate of group 0 to 1.0000e-10.\nscore:  0.5984251968503937\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 190/190 [01:58<00:00,  1.60it/s]\n100%|██████████| 22/22 [00:11<00:00,  1.91it/s]\n","output_type":"stream"},{"name":"stdout","text":"Adjusting learning rate of group 0 to 1.0000e-10.\nscore:  0.5866141732283464\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 190/190 [01:58<00:00,  1.61it/s]\n100%|██████████| 22/22 [00:12<00:00,  1.81it/s]\n","output_type":"stream"},{"name":"stdout","text":"Adjusting learning rate of group 0 to 1.0000e-12.\nscore:  0.594488188976378\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 190/190 [01:57<00:00,  1.61it/s]\n100%|██████████| 22/22 [00:13<00:00,  1.68it/s]\n","output_type":"stream"},{"name":"stdout","text":"Adjusting learning rate of group 0 to 1.0000e-12.\nscore:  0.6062992125984252\nScore Improved\nEpoch 13 - Save Best Score: 0.6063\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 190/190 [01:57<00:00,  1.61it/s]\n100%|██████████| 22/22 [00:12<00:00,  1.81it/s]\n","output_type":"stream"},{"name":"stdout","text":"Adjusting learning rate of group 0 to 1.0000e-12.\nscore:  0.6023622047244095\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 190/190 [01:57<00:00,  1.62it/s]\n100%|██████████| 22/22 [00:11<00:00,  1.85it/s]\n","output_type":"stream"},{"name":"stdout","text":"Adjusting learning rate of group 0 to 1.0000e-14.\nscore:  0.5905511811023622\n","output_type":"stream"}]},{"cell_type":"code","source":"test_dataset = TestDataset(test, transform=get_transforms(data='valid'))\ntest_loader = DataLoader(test_dataset, batch_size=1, shuffle=False, \n                          num_workers=CFG.num_workers, pin_memory=True, drop_last=False)\ncheck_point = torch.load('./'+f'{CFG.model_name}_best.pth')\nmodel = CustomNet(CFG.model_name, pretrained=True)\nmodel.to(device)\nmodel.load_state_dict(check_point['model'])\npred = test_fun(test_loader, model, device)","metadata":{"execution":{"iopub.status.busy":"2022-10-24T07:03:32.541295Z","iopub.execute_input":"2022-10-24T07:03:32.542129Z","iopub.status.idle":"2022-10-24T07:04:10.715754Z","shell.execute_reply.started":"2022-10-24T07:03:32.542080Z","shell.execute_reply":"2022-10-24T07:04:10.714479Z"},"trusted":true},"execution_count":27,"outputs":[]},{"cell_type":"code","source":"test['tar'] = pred","metadata":{"execution":{"iopub.status.busy":"2022-10-24T07:04:10.717716Z","iopub.execute_input":"2022-10-24T07:04:10.718381Z","iopub.status.idle":"2022-10-24T07:04:10.724551Z","shell.execute_reply.started":"2022-10-24T07:04:10.718347Z","shell.execute_reply":"2022-10-24T07:04:10.723585Z"},"trusted":true},"execution_count":28,"outputs":[]},{"cell_type":"code","source":"submission_df = test.drop(['path'], axis=1)\nsubmission_df.to_csv(\"submission.csv\", index=False)","metadata":{"execution":{"iopub.status.busy":"2022-10-24T07:04:10.726257Z","iopub.execute_input":"2022-10-24T07:04:10.727068Z","iopub.status.idle":"2022-10-24T07:04:10.746558Z","shell.execute_reply.started":"2022-10-24T07:04:10.727030Z","shell.execute_reply":"2022-10-24T07:04:10.745339Z"},"trusted":true},"execution_count":29,"outputs":[]},{"cell_type":"code","source":"submission_df","metadata":{"execution":{"iopub.status.busy":"2022-10-24T07:04:10.749612Z","iopub.execute_input":"2022-10-24T07:04:10.750387Z","iopub.status.idle":"2022-10-24T07:04:10.766229Z","shell.execute_reply.started":"2022-10-24T07:04:10.750342Z","shell.execute_reply":"2022-10-24T07:04:10.765168Z"},"trusted":true},"execution_count":30,"outputs":[{"execution_count":30,"output_type":"execute_result","data":{"text/plain":"             id  tar\n0    10002998.0    3\n1    10003172.0    5\n2    20004712.0    4\n3    20004205.0    4\n4    20000346.0    3\n..          ...  ...\n553  20001798.0    5\n554  10006153.0    5\n555  10010660.0    4\n556  10008746.0    5\n557  20004939.0    5\n\n[558 rows x 2 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>tar</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>10002998.0</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>10003172.0</td>\n      <td>5</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>20004712.0</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>20004205.0</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>20000346.0</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>553</th>\n      <td>20001798.0</td>\n      <td>5</td>\n    </tr>\n    <tr>\n      <th>554</th>\n      <td>10006153.0</td>\n      <td>5</td>\n    </tr>\n    <tr>\n      <th>555</th>\n      <td>10010660.0</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>556</th>\n      <td>10008746.0</td>\n      <td>5</td>\n    </tr>\n    <tr>\n      <th>557</th>\n      <td>20004939.0</td>\n      <td>5</td>\n    </tr>\n  </tbody>\n</table>\n<p>558 rows × 2 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"markdown","source":"### Now click on the \"Submit\" button to submit the notebook\n### NOTE: We expect everyone to generate such notebooks for your final submission. Only the teams with notebook submitted against their final submission will be considered for prize money!","metadata":{}},{"cell_type":"markdown","source":"### Things to try next:\n* Try different architectures, optimizers, loss functions etc.\n* Think of ways of tackling data imbalance problem.\n* Try different image size\n* Try Ensembling methods.\n* Apply semi supervised learning.","metadata":{}},{"cell_type":"markdown","source":"### PS: This competition is hosted to promote learning. So we request you to publish your baseline models via Kaggle kernels and discuss on the discussion tab to help others learn. Thanks!","metadata":{}},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}